# unicode_denormalizer.py
#
# Demonstration of the pyparsing's transform_string() method, to
# convert identifiers in Python source code to equivalent Unicode
# characters. Python's compiler automatically normalizes Unicode
# characters back to their ASCII equivalents, so that identifiers may
# be rewritten using other Unicode characters, and normalize back to
# the same identifier. For instance, Python treats "print" and "ùï°ùìª·µ¢ùìÉùòÅ"
# and "ùñïùíìùóÇùëõ·µó" all as the same identifier.
#
# The converter must take care to *only* transform identifiers -
# Python keywords must always be represented in base ASCII form. To
# skip over keywords, they are added to the parser/transformer, but
# contain no transforming parse action.
#
# The converter also detects identifiers in placeholders within f-strings.
#
# Copyright 2022, by Paul McGuire
#
import keyword
import random
import unicodedata

import pyparsing as pp
ppu = pp.pyparsing_unicode

_¬∑ = "_¬∑"
ident_chars = (
    "ABCDEFGHIJKLMNOPQRSTUVWXYZ"
    "abcdefghijklmnopqrstuvwxyz"
    "0123456789" + _¬∑
)

# build map of each ASCII character to a list of
# all the characters in the Basic Multilingual Plane
# that NFKC normalize back to that ASCII character
ident_char_map = {}.fromkeys(ident_chars, "")
for ch in ppu.BMP.identbodychars:
    normal = unicodedata.normalize("NFKC", ch)
    if normal in ident_char_map:
        ident_char_map[normal] += ch

# ligatures will also normalize back to ASCII
ligature_map = {
    'ffl': 'Ô¨Ñ Ô¨Ñ Ô¨Äl fÔ¨Ç ffl',
    'ffi': 'Ô¨É Ô¨É Ô¨Äi fÔ¨Å ffi',
    'ff': 'Ô¨Ä ff',
    'fi': 'Ô¨Å fi',
    'fl': 'Ô¨Ç fl',

    'ij': 'ij ƒ≥',
    'lj': 'lj «â',
    'nj': 'nj «å',
    'dz': 'dz «≥',
    'ii': 'ii ‚Ö±',
    'iv': 'iv ‚Ö≥',
    'vi': 'vi ‚Öµ',
    'ix': 'ix ‚Ö∏',
    'xi': 'xi ‚Ö∫',
}
ligature_transformer = pp.oneOf(ligature_map).add_parse_action(lambda t: random.choice(ligature_map[t[0]].split()))


def make_mixed_font(t):
    t_0 = t[0][0]
    ret = ['_' if t_0 == '_' else random.choice(ident_char_map.get(t_0, t_0))]
    t_rest = ligature_transformer.transform_string(t[0][1:])
    ret.extend(random.choice(ident_char_map.get(c, c)) for c in t_rest)
    return ''.join(ret)


# define a pyparsing expression to match any identifier
identifier = pp.pyparsing_common.identifier
identifier.add_parse_action(make_mixed_font)

# match quoted strings (which may be f-strings)
python_quoted_string = pp.Opt(pp.Char("fF")("f_string_prefix")) + (
        pp.python_quoted_string
)("quoted_string_body")


def mix_fstring_expressions(t):
    if not t.f_string_prefix:
        return
    fstring_arg = pp.QuotedString("{", end_quote_char="}")
    fstring_arg.add_parse_action(lambda tt: "{" + transformer.transform_string(tt[0]) + "}")
    ret = t.f_string_prefix + fstring_arg.transform_string(t.quoted_string_body)
    return ret


python_quoted_string.add_parse_action(mix_fstring_expressions)

# match keywords separately from identifiers - keywords must be kept in their
# original ASCII
any_keyword = pp.one_of(
    keyword.kwlist + getattr(keyword, "softkwlist", []),
    as_keyword=True
)

# quoted strings and keywords will be parsed, but left untransformed
transformer = python_quoted_string | any_keyword | identifier


def demo():
    import textwrap
    hello_source = textwrap.dedent("""
    def hello():
        try:
            hello_ = "Hello"
            world_ = "World"
            print(f"{hello_}, {world_}!")
        except TypeError as exc:
            print("failed: {}".format(exc))
    
    if __name__ == "__main__":
        hello()
    """)
    source = hello_source

    transformed = transformer.transform_string(source)
    print(transformed)

    # does it really work?
    code = compile(transformed, source, mode="exec")
    exec(code)

    if 0:
        # pick some code from the stdlib
        import unittest.util as lib_module
        import inspect
        source = inspect.getsource(lib_module)
        transformed = transformer.transform_string(source)
        print()
        print(transformed)

if __name__ == '__main__':
    demo()
